model,result,accuracy,macro_precision,macro_recall,macro_f1,micro_precision,micro_recall,micro_f1,weighted_precision,weighted_recall,weighted_f1,avg_time_taken
llama3.1,result1,67.91,43.8,39.72,41.54,67.93,67.91,67.92,79.02,67.91,72.95,1.4
llama3.1,result2,68.97,44.87,40.53,42.49,68.97,68.97,68.97,80.15,68.97,74.06,1.41
llama3.1,result3,68.17999999999999,44.28,39.96,41.92,68.19,68.17999999999999,68.17999999999999,79.2,68.17999999999999,73.2,1.42
mistral,result1,77.25999999999999,47.870000000000005,41.52,44.06,77.33,77.25999999999999,77.29,81.08,77.25999999999999,78.79,1.42
mistral,result2,77.56,47.52,41.56,43.93,77.61,77.56,77.59,80.76,77.56,78.8,1.42
mistral,result3,77.35,47.870000000000005,41.56,44.07,77.37,77.35,77.36,80.96,77.35,78.78,1.43
gemma2,result1,66.36,46.300000000000004,41.75,43.32,66.46,66.36,66.41,83.11,66.36,73.31,1.51
gemma2,result2,65.83,46.2,41.38,43.08,65.95,65.83,65.89,82.91,65.83,72.91,1.53
gemma2,result3,66.43,46.379999999999995,41.78,43.38,66.53999999999999,66.43,66.49000000000001,83.25,66.43,73.41,1.54
phi4,result1,63.239999999999995,47.43,33.82,39.22,63.24999999999999,63.239999999999995,63.24999999999999,81.8,63.239999999999995,71.11,2.99
phi4,result2,63.13999999999999,47.33,33.79,39.18,63.160000000000004,63.13999999999999,63.14999999999999,81.89999999999999,63.13999999999999,71.12,3.0
phi4,result3,63.13999999999999,47.980000000000004,33.87,39.44,63.13999999999999,63.13999999999999,63.13999999999999,82.39999999999999,63.13999999999999,71.28,3.02
deepseek-r1:8b,result1,72.57000000000001,42.64,37.84,39.92,72.65,72.57000000000001,72.61,76.96,72.57000000000001,74.56,4.42
deepseek-r1:8b,result2,71.64,42.1,37.55,39.57,71.65,71.64,71.64,76.46,71.64,73.88,4.46
deepseek-r1:8b,result3,72.38,43.309999999999995,38.3,40.510000000000005,72.43,72.38,72.41,77.49000000000001,72.38,74.74,4.45
