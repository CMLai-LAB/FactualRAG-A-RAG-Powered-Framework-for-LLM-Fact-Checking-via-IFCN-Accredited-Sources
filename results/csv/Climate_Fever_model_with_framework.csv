model,result,accuracy,macro_precision,macro_recall,macro_f1,micro_precision,micro_recall,micro_f1,weighted_precision,weighted_recall,weighted_f1,avg_time_taken
llama3.1,result1,49.44,36.730000000000004,44.76,38.49,49.44,49.44,49.44,41.11,49.44,42.809999999999995,16.51
llama3.1,result2,50.0,53.04,45.49,39.57,50.0,50.0,50.0,53.64,50.0,43.56,17.14
llama3.1,result3,50.56,37.9,45.71,39.61,50.56,50.56,50.56,42.46,50.56,44.12,17.62
mistral,result1,44.940000000000005,44.25,41.370000000000005,36.63,44.940000000000005,44.940000000000005,44.940000000000005,48.32,44.940000000000005,39.94,16.34
mistral,result2,41.57,40.400000000000006,38.279999999999994,34.11,41.57,41.57,41.57,43.980000000000004,41.57,37.15,14.64
mistral,result3,47.19,49.99,44.65,42.25,47.19,47.19,47.19,52.370000000000005,47.19,44.37,13.9
gemma2,result1,47.75,40.43,43.41,36.93,47.75,47.75,47.75,45.410000000000004,47.75,41.06,21.92
gemma2,result2,46.63,43.44,42.61,37.08,46.89,46.63,46.760000000000005,47.099999999999994,46.63,40.79,23.95
gemma2,result3,46.63,38.93,42.4,36.16,46.63,46.63,46.63,43.68,46.63,40.17,24.31
phi4,result1,46.07,44.42,42.46,39.129999999999995,46.07,46.07,46.07,48.02,46.07,42.480000000000004,27.31
phi4,result2,48.309999999999995,42.8,44.11,38.83,48.309999999999995,48.309999999999995,48.309999999999995,47.04,48.309999999999995,42.77,28.19
phi4,result3,47.75,43.53,43.79,39.08,47.75,47.75,47.75,46.86,47.75,42.66,28.6
deepseek-r1:8b,result1,50.0,44.54,45.86,42.34,50.57000000000001,50.0,50.28,47.339999999999996,50.0,45.97,37.16
deepseek-r1:8b,result2,47.75,46.400000000000006,44.17,40.739999999999995,48.02,47.75,47.89,48.41,47.75,43.76,39.44
deepseek-r1:8b,result3,51.690000000000005,48.809999999999995,47.63,43.97,51.690000000000005,51.690000000000005,51.690000000000005,50.78,51.690000000000005,47.36,39.35
