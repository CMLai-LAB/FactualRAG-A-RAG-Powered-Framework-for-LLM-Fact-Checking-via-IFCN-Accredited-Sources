model,result,accuracy,macro_precision,macro_recall,macro_f1
llama3,result1,0.486,0.369,0.44,0.382
llama3,result2,0.463,0.361,0.415,0.359
llama3,result3,0.463,0.408,0.422,0.368
mistral,result1,0.449,0.442,0.414,0.366
mistral,result2,0.416,0.404,0.383,0.341
mistral,result3,0.472,0.5,0.446,0.423
gemma2,result1,0.478,0.404,0.434,0.369
gemma2,result2,0.466,0.434,0.426,0.371
gemma2,result3,0.466,0.389,0.424,0.362
phi4,result1,0.461,0.444,0.425,0.391
phi4,result2,0.483,0.428,0.441,0.388
phi4,result3,0.478,0.435,0.438,0.391
deepseek-r1:8b,result1,0.5,0.445,0.459,0.423
deepseek-r1:8b,result2,0.478,0.464,0.442,0.407
deepseek-r1:8b,result3,0.517,0.488,0.476,0.44
