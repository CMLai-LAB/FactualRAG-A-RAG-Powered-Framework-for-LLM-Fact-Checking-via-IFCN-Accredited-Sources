model,result,accuracy,macro_precision,macro_recall,macro_f1
llama3,result1,0.938,0.607,0.6,0.603
llama3,result2,0.937,0.607,0.597,0.602
llama3,result3,0.931,0.599,0.594,0.596
mistral,result1,0.882,0.619,0.533,0.569
mistral,result2,0.883,0.622,0.53,0.567
mistral,result3,0.887,0.625,0.536,0.572
gemma2,result1,0.94,0.635,0.586,0.608
gemma2,result2,0.94,0.633,0.589,0.609
gemma2,result3,0.941,0.637,0.586,0.609
phi4,result1,0.932,0.626,0.588,0.606
phi4,result2,0.927,0.626,0.584,0.603
phi4,result3,0.926,0.621,0.582,0.6
deepseek-r1:8b,result1,0.76,0.485,0.428,0.454
deepseek-r1:8b,result2,0.769,0.495,0.43,0.459
deepseek-r1:8b,result3,0.765,0.495,0.432,0.46
