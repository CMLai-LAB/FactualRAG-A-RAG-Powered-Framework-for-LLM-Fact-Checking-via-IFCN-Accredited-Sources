model,result,accuracy,macro_precision,macro_recall,macro_f1,micro_precision,micro_recall,micro_f1,weighted_precision,weighted_recall,weighted_f1,avg_time_taken
llama3.1,result1,54.49,54.53,50.09,44.76,54.49,54.49,54.49,56.11000000000001,54.49,48.46,1.58
llama3.1,result2,53.93,59.72,49.57,44.330000000000005,53.93,53.93,53.93,59.98,53.93,47.96,1.56
llama3.1,result3,56.74,53.480000000000004,51.73,45.96,56.74,56.74,56.74,55.22,56.74,50.24999999999999,1.61
mistral,result1,51.12,42.03,46.47,40.949999999999996,51.41,51.12,51.27,45.35,51.12,45.12,1.38
mistral,result2,52.81,48.92,48.17,43.11,53.11,52.81,52.959999999999994,50.88,52.81,47.11,1.39
mistral,result3,52.81,49.38,48.199999999999996,43.11,53.11,52.81,52.959999999999994,51.42,52.81,47.099999999999994,1.39
gemma2,result1,57.3,61.38,52.42,47.71,57.63,57.3,57.46,61.83,57.3,51.82,1.69
gemma2,result2,54.49,60.050000000000004,49.97,45.43,55.11000000000001,54.49,54.800000000000004,60.34,54.49,49.24,1.7
gemma2,result3,55.059999999999995,56.68,50.660000000000004,46.73,55.37,55.059999999999995,55.21,57.709999999999994,55.059999999999995,50.349999999999994,1.68
phi4,result1,53.37,53.21,50.3,48.52,53.37,53.37,53.37,55.44,53.37,51.09,3.41
phi4,result2,55.059999999999995,55.36,51.800000000000004,49.980000000000004,55.059999999999995,55.059999999999995,55.059999999999995,57.29,55.059999999999995,52.62,3.4
phi4,result3,51.12,50.33,48.11,45.96,51.12,51.12,51.12,52.93,51.12,48.6,3.42
deepseek-r1:8b,result1,50.56,52.76,47.46,45.7,50.56,50.56,50.56,52.849999999999994,50.56,47.86,4.59
deepseek-r1:8b,result2,51.690000000000005,60.51,48.07,45.28,51.690000000000005,51.690000000000005,51.690000000000005,59.07,51.690000000000005,47.86,4.6
deepseek-r1:8b,result3,50.0,45.050000000000004,45.95,41.77,50.0,50.0,50.0,47.75,50.0,45.29,4.65
