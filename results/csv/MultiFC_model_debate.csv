model,result,accuracy,macro_precision,macro_recall,macro_f1,micro_precision,micro_recall,micro_f1,weighted_precision,weighted_recall,weighted_f1,avg_time_taken
llama3.1,result1,92.46,60.0,59.58,59.78,93.11,92.46,92.78,94.07,92.46,93.25,54.59
llama3.1,result2,92.27,60.33,58.60999999999999,59.45,92.86,92.27,92.57,93.78,92.27,93.01,55.96
llama3.1,result3,92.60000000000001,60.5,58.98,59.72,93.19,92.60000000000001,92.89,93.97,92.60000000000001,93.27,56.78
mistral,result1,90.2,62.44,54.99000000000001,58.14,90.32,90.2,90.25999999999999,93.78999999999999,90.2,91.64999999999999,51.93
mistral,result2,89.34,61.79,53.510000000000005,56.87,89.42,89.34,89.38000000000001,92.93,89.34,90.67,50.5
mistral,result3,90.11,62.31,54.379999999999995,57.64,90.16999999999999,90.11,90.14,93.4,90.11,91.33,48.61
gemma2,result1,93.89,63.53,58.120000000000005,60.480000000000004,94.8,93.89,94.34,95.67999999999999,93.89,94.58,73.54
gemma2,result2,93.82000000000001,63.57000000000001,57.879999999999995,60.35,94.91000000000001,93.82000000000001,94.36,95.72,93.82000000000001,94.54,75.46
gemma2,result3,93.82000000000001,63.32,58.15,60.419999999999995,94.69999999999999,93.82000000000001,94.26,95.48,93.82000000000001,94.46,75.44
phi4,result1,93.16,63.54,58.17,60.56,93.36,93.16,93.26,95.55,93.16,94.17999999999999,100.57
phi4,result2,93.0,63.0,57.989999999999995,60.23,93.26,93.0,93.13,95.17999999999999,93.0,93.93,102.48
phi4,result3,93.12,63.07000000000001,58.36,60.49,93.33,93.12,93.23,95.28999999999999,93.12,94.07,102.35
deepseek-r1:8b,result1,79.77,50.519999999999996,41.97,44.82,80.67999999999999,79.77,80.22,82.78,79.77,80.42,134.5
deepseek-r1:8b,result2,80.64,51.71,42.68,45.660000000000004,81.77,80.64,81.2,83.72,80.64,81.25,138.41
deepseek-r1:8b,result3,80.03,50.660000000000004,42.43,45.26,80.94,80.03,80.47999999999999,83.0,80.03,80.74,138.54
