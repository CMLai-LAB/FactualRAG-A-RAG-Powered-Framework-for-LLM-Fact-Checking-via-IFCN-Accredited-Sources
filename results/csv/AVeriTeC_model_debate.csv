model,result,accuracy,macro_precision,macro_recall,macro_f1,micro_precision,micro_recall,micro_f1,weighted_precision,weighted_recall,weighted_f1,avg_time_taken
llama3.1,result1,72.5,55.93,52.01,53.169999999999995,74.41,72.5,73.44000000000001,71.2,72.5,71.48,58.5
llama3.1,result2,72.08,54.290000000000006,51.019999999999996,51.870000000000005,73.56,72.08,72.82,70.06,72.08,70.67999999999999,60.93
llama3.1,result3,72.86,52.239999999999995,50.62,51.05,73.95,72.86,73.4,70.66,72.86,71.55,64.49
mistral,result1,66.60000000000001,55.13,48.69,49.53,67.06,66.60000000000001,66.83,70.47,66.60000000000001,66.64999999999999,57.33
mistral,result2,69.69999999999999,58.67,52.44,53.269999999999996,70.19,69.69999999999999,69.94,72.63,69.69999999999999,69.27,46.67
mistral,result3,68.43,56.95,50.89,51.77,68.67,68.43,68.55,71.17999999999999,68.43,68.01,54.09
gemma2,result1,73.4,59.39,53.61,55.7,75.33999999999999,73.4,74.36,73.97,73.4,72.99,79.16
gemma2,result2,74.1,60.260000000000005,54.790000000000006,56.82000000000001,75.78,74.1,74.92999999999999,74.3,74.1,73.61,83.84
gemma2,result3,73.68,61.129999999999995,55.03,57.220000000000006,75.36,73.68,74.51,74.37,73.68,73.26,83.86
phi4,result1,71.94,59.78,55.14,55.900000000000006,72.3,71.94,72.11999999999999,74.69,71.94,72.1,104.6
phi4,result2,71.81,60.150000000000006,55.21,56.15,72.50999999999999,71.81,72.16,74.9,71.81,72.16,107.25
phi4,result3,71.39,59.099999999999994,54.669999999999995,55.489999999999995,71.89,71.39,71.64,74.05000000000001,71.39,71.63000000000001,108.98
deepseek-r1:8b,result1,66.74,50.01,43.919999999999995,44.76,67.11,66.74,66.92,64.74,66.74,63.62,142.72
deepseek-r1:8b,result2,66.36999999999999,51.04,45.11,46.28,67.06,66.36999999999999,66.71000000000001,64.92999999999999,66.36999999999999,63.94,143.7
deepseek-r1:8b,result3,67.5,53.82,46.37,47.77,68.07,67.5,67.78,66.49000000000001,67.5,64.81,145.26
